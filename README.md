# Open-Set Recognition in the Age of Vision-Language Models

Are vision-language models (VLMs) open-set models because they are trained on internet-scale datasets? No - VLMs introduce closed-set assumptions via their finite query set, making them vulnerable to open-set conditions. 

![Image description](images/githubdisplay.png)

This repository willl *soon* contain the benchmark evaluation code from the paper:

**Open-Set Recognition in the Age of Vision-Language Models**

*Dimity Miller, Niko Suenderhauf, Alex Kenna, Keita Mason*

To appear at the 2024 European Conference on Computer Vision (ECCV).

[Preprint]([https://openaccess.thecvf.com/content/WACV2021/papers/Miller_Class_Anchor_Clustering_A_Loss_for_Distance-Based_Open_Set_Recognition_WACV_2021_paper.pdf](https://arxiv.org/pdf/2403.16528))

If you use this work, please cite:

```text
@article{miller2024open,
  title={Open-Set Recognition in the Age of Vision-Language Models},
  author={Miller, Dimity and S{\"u}nderhauf, Niko and Kenna, Alex and Mason, Keita},
  journal={arXiv preprint arXiv:2403.16528},
  year={2024}
}
```


**Contact**

If you have any questions or comments, please contact [Dimity Miller](mailto:d24.miller@qut.edu.au).
